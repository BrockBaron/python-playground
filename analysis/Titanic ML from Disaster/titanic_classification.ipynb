{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "\n",
    "Author: Jingwen ZHENG<br>\n",
    "Update: 2019-05-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- Project understanding\n",
    "- Objectif\n",
    "- Practice skills\n",
    "- Python packages to be applied\n",
    "- Import data\n",
    "- Data description\n",
    "- Data cleaning\n",
    "- Data analysis\n",
    "- Build preprocessing pipeline\n",
    "- Train data\n",
    "- Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we need to analyse what sorts of people were likely to survive.<br>\n",
    "In particular, we also need to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3\n",
    "- Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python packages to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimension train_df:', train_df.shape)\n",
    "print('Dimension test_df:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> There are missing data in \"Age\", \"Cabin\" and \"Embarked\", especially \"Cabin\" whose 77% data are missing. So we will ignore it during the analysis.<br>\n",
    "What should we do on missing data of \"Age\"? We might replace null by median age.<br>\n",
    "Same for \"Embarked\"<br>\n",
    "=> On average, the probability of one passenger being survived is 38%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "train_df['Embarked'].fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.hist(bins=40, figsize=(18, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix between numerical values and \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 8)})\n",
    "\n",
    "sns.heatmap(train_df[['Survived', 'SibSp', 'Parch', 'Age', 'Pclass', 'Fare']].corr(),\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this correlation heatmap, we find that \"Survived\" possibility is slightly negative correlated with \"Age\", which means that the older the passenger is, the more possible he will be survived; it's significant at 5%. \"Pclass\" and \"Fare are negatively correlated which is logic: the better class is, the more expensive fare is. \"Pclass\" is also negative correlated with \"Survived\" possibility, maybe the top class's location is nearer to exit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibsp_survived_plt = sns.FacetGrid(train_df, col='Survived', height=4, aspect=1)\n",
    "sibsp_survived_plt.map(sns.distplot, 'SibSp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of survived people didn't have siblings / spouses aboard the Titanic, other survived majority is people who had one sibling / spouse aboard the Titanic. Very few people who had more than one sibling / spouse aboard the Titanic were survived, since it's difficult to survive all passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibsp_sex_survived_plt = sns.factorplot(x='SibSp',\n",
    "                                        col='Survived',\n",
    "                                        data=train_df,\n",
    "                                        hue='Sex',\n",
    "                                        kind='count',\n",
    "                                        palette='muted',\n",
    "                                        size=4,\n",
    "                                        aspect=1)\n",
    "sibsp_sex_survived_plt.despine(left=True)\n",
    "sibsp_sex_survived_plt.set_ylabels('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all survivals, the majority was female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parch vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_survived_plt = sns.FacetGrid(train_df, col='Survived', height=4, aspect=1)\n",
    "parch_survived_plt.map(sns.distplot, 'Parch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as relation between SibSp vs. Survived, most of survived people didn't have parents / children aboard the Titanic, other survived majority is people who had one parent / child aboard the Titanic. Very few people who had more than one parent / child aboard the Titanic were survived, since it's difficult to survive all passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_sex_survived_plt = sns.factorplot(x='Parch',\n",
    "                                        col='Survived',\n",
    "                                        data=train_df,\n",
    "                                        hue='Sex',\n",
    "                                        kind='count',\n",
    "                                        palette='muted',\n",
    "                                        size=4,\n",
    "                                        aspect=1)\n",
    "parch_sex_survived_plt.despine(left=True)\n",
    "parch_sex_survived_plt.set_ylabels('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all survivals, the majority was female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_survived_plt = sns.FacetGrid(train_df, col='Survived', height=4, aspect=1)\n",
    "age_survived_plt.map(sns.distplot, 'Age')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Age\" distribution is nearly a Normal distribution. We find that the most survived are the people around 25 year-old, which might because there were lots of younger on the board. However, people older than 50 year-old is less survived, which is not extractly same as analysis above. The graph below will explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs. Sex vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex_survived_plt = sns.FacetGrid(train_df , hue='Survived' , aspect=4 , row = 'Sex' )\n",
    "age_sex_survived_plt.map( sns.kdeplot, 'Age' , shade= True )\n",
    "age_sex_survived_plt.set( xlim=( 0 , train_df['Age'].max() ) )\n",
    "age_sex_survived_plt.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[(train_df['Survived']==0) & (train_df['Age']>50)].Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[(train_df['Survived']==1) & (train_df['Age']>50)].Sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this plot, we find that both female and male passengers are nearly half survived, since the shadow surface of \"Survived\" and \"Non-survived\" are nearly the same. But the survived possibility is different on ages for female and male. For female passengers, the ones that older than 27 year-old have a little bit more chance to be survived than others. For male passengers, the one who is younger than 15 years old or older than 34 years old are more likely to be survived than men between 16 and 32 years old, which because they help other passengers to be alive.<br>\n",
    "Moreover, let's pay attention to the passengers that were older than 50 year-old. According to the graph \"Age vs. Survived\" we find that people older than 50 year-old is less survived, which is not extractly same as correlation analysis. But from this graph we can easily understand why: most of older _passengers_ were male, most of the older _survival_ were female, and they were nearly all survived. So in fact, older female passengers had much more chance to be survived than older male passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_survived_plt = sns.FacetGrid(train_df, col='Survived', height=4, aspect=1)\n",
    "pclass_survived_plt.map(sns.distplot, 'Pclass')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the class of survived passengers, it's almost same for each class, the possibility for class 1 is a bit more higher than others. However, non-survived probability of class 3 is 3 times of class 1 and class 2, respectively. This is coherent with analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embarked_survived_plt = sns.factorplot(data=train_df,\n",
    "                                       x='Embarked',\n",
    "                                       y='Survived',\n",
    "                                       size=6,\n",
    "                                       kind='bar',\n",
    "                                       palette='muted')\n",
    "embarked_survived_plt.despine(left=True)\n",
    "embarked_survived_plt.set_ylabels('Survival probability')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passengers who came from Cherbourg (`Embarked='C'`) had more chance to be survived, so we'll study why they were most survived in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pclass_embarked_survived_plt = sns.factorplot(x='Pclass',\n",
    "                                              col='Survived',\n",
    "                                              data=train_df,\n",
    "                                              hue='Embarked',\n",
    "                                              kind='count',\n",
    "                                              palette='muted',\n",
    "                                              size=4,\n",
    "                                              aspect=1)\n",
    "pclass_embarked_survived_plt.despine(left=True)\n",
    "pclass_embarked_survived_plt.set_ylabels('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this graph, we find that the majority of passengers came from Southampton (`Embarked='S'`) and lots of them chose class 3 which decrease the survived chance. However, the marjority of passengers who came from Cherbourg (`Embarked='C'`) were in class 1, such their chance to be survived was more than others, which is coherent with result above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build preprocessing pipeline\n",
    "Inspired by https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_attribs = ['Pclass', 'Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('select_numeric', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('select_numeric', DataFrameSelector(cat_attribs)),\n",
    "    ('imputer', MostFrequentImputer()),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)) # return an array\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join 2 pipelines into a single pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[('num_pipeline', num_pipeline),\n",
    "                                               ('cat_pipeline', cat_pipeline)]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_pipeline.fit_transform(train_df)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = full_pipeline.fit_transform(test_df)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support-vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params = {'kernel': ['rbf'],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1],\n",
    "              'C': [1, 10, 50, 100, 200, 300, 1000]}\n",
    "svr_gridsearch = GridSearchCV(SVC(random_state=42),\n",
    "                              svr_params,\n",
    "                              cv=StratifiedKFold(n_splits=10),\n",
    "                              scoring='accuracy',\n",
    "                              n_jobs=-1)\n",
    "svr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svr = svr_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree_params = {'max_features': [1, 3, 10],\n",
    "                       'min_samples_split': [2, 3, 10],\n",
    "                       'min_samples_leaf': [1, 3, 10]}\n",
    "decisionTree_gridsearch = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                                       decisionTree_params,\n",
    "                                       cv=StratifiedKFold(n_splits=10),\n",
    "                                       scoring='accuracy',\n",
    "                                       n_jobs=-1)\n",
    "decisionTree_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_decisionTree = decisionTree_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_decisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmFrst_params = {'max_depth': [None],\n",
    "                  'max_features': [1, 3, 10],\n",
    "                  'min_samples_split': [2, 3, 10],\n",
    "                  'min_samples_leaf': [1, 3, 10],\n",
    "                  'bootstrap': [False],\n",
    "                  'n_estimators':[100,300],\n",
    "                  'criterion': ['gini']}\n",
    "rdmFrst_gridsearch = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                                  rdmFrst_params,\n",
    "                                  cv=StratifiedKFold(n_splits=10),\n",
    "                                  scoring='accuracy',\n",
    "                                  n_jobs=-1)\n",
    "rdmFrst_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rdmFrst = rdmFrst_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_rdmFrst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logReg = log_reg.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "ada_params = {'base_estimator__criterion': ['gini', 'entropy'],\n",
    "              'base_estimator__splitter': ['best', 'random'],\n",
    "              'algorithm': ['SAMME', 'SAMME.R'],\n",
    "              'n_estimators': [1, 2],\n",
    "              'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 1.5]}\n",
    "\n",
    "ada_gridsearch = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(random_state=42)),\n",
    "                              param_grid = ada_params,\n",
    "                              cv=StratifiedKFold(n_splits=10),\n",
    "                              scoring='accuracy',\n",
    "                              n_jobs= -1)\n",
    "\n",
    "ada_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "extraTree_params = {'max_depth': [None],\n",
    "                    'max_features': [1, 3, 10],\n",
    "                    'min_samples_split': [2, 3, 10],\n",
    "                    'min_samples_leaf': [1, 3, 10],\n",
    "                    'bootstrap': [False],\n",
    "                    'n_estimators': [100, 300],\n",
    "                    'criterion': ['gini']}\n",
    "extraTree_gridsearch = GridSearchCV(ExtraTreesClassifier(random_state=42),\n",
    "                                    extraTree_params,\n",
    "                                    cv=StratifiedKFold(n_splits=10),\n",
    "                                    scoring='accuracy',\n",
    "                                    n_jobs=-1)\n",
    "extraTree_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraTree_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_extraTree = extraTree_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_extraTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "gbrt_params = {'n_estimators': [100, 200, 300],\n",
    "               'loss': ['deviance'],\n",
    "               'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'max_depth': [4, 8],\n",
    "               'min_samples_leaf': [100, 150],\n",
    "               'max_features': [0.1, 0.3]}\n",
    "gbrt_gridsearch = GridSearchCV(GradientBoostingClassifier(random_state=42),\n",
    "                               gbrt_params,\n",
    "                               cv=StratifiedKFold(n_splits=10),\n",
    "                               scoring='accuracy',\n",
    "                               n_jobs=-1)\n",
    "gbrt_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbrt = gbrt_gridsearch.best_estimator_.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_gbrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_hard_clf = VotingClassifier(\n",
    "    estimators=[('svm', svr_gridsearch.best_estimator_),\n",
    "                ('dt', decisionTree_gridsearch.best_estimator_),\n",
    "                ('rf', rdmFrst_gridsearch.best_estimator_),\n",
    "                ('lr', log_reg),\n",
    "                ('ada', ada_gridsearch.best_estimator_),\n",
    "                ('extraTree', extraTree_gridsearch.best_estimator_),\n",
    "                ('gbrt', gbrt_gridsearch.best_estimator_)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_hard_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_voting_hard = voting_hard_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_voting_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_hard_clf_90 = VotingClassifier(\n",
    "    estimators=[('svm', svr_gridsearch.best_estimator_),\n",
    "                ('rf', rdmFrst_gridsearch.best_estimator_),\n",
    "                ('ada', ada_gridsearch.best_estimator_),\n",
    "                ('extraTree', extraTree_gridsearch.best_estimator_),\n",
    "                ('gbrt', gbrt_gridsearch.best_estimator_)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_hard_clf_90.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_voting_hard_90 = voting_hard_clf_90.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_voting_hard_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_gridsearch.best_estimator_.probability = True\n",
    "voting_soft_clf = VotingClassifier(\n",
    "    estimators=[('svm', svr_gridsearch.best_estimator_),\n",
    "                ('dt', decisionTree_gridsearch.best_estimator_),\n",
    "                ('rf', rdmFrst_gridsearch.best_estimator_),\n",
    "                ('lr', log_reg),\n",
    "                ('ada', ada_gridsearch.best_estimator_),\n",
    "                ('extraTree', extraTree_gridsearch.best_estimator_),\n",
    "                ('gbrt', gbrt_gridsearch.best_estimator_)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_soft_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_voting_soft = voting_soft_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_voting_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different models' accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_df = pd.DataFrame({'Models': ['SVM',\n",
    "                                             'Decision Trees',\n",
    "                                             'Random Forest',\n",
    "                                             'Logistic Regression',\n",
    "                                             'AdaBoost',\n",
    "                                             'Extra Trees',\n",
    "                                             'Gradient Boosting',\n",
    "                                             'Hard voting',\n",
    "                                             'Hard voting gt 90pct',\n",
    "                                             'Soft voting'],\n",
    "                                  'Accuracy score': [accuracy_score(y_train, y_pred_svr),\n",
    "                                                     accuracy_score(y_train, y_pred_decisionTree),\n",
    "                                                     accuracy_score(y_train, y_pred_rdmFrst),\n",
    "                                                     accuracy_score(y_train, y_pred_logReg),\n",
    "                                                     accuracy_score(y_train, y_pred_ada),\n",
    "                                                     accuracy_score(y_train, y_pred_extraTree),\n",
    "                                                     accuracy_score(y_train, y_pred_gbrt),\n",
    "                                                     accuracy_score(y_train, y_pred_voting_hard),\n",
    "                                                     accuracy_score(y_train, y_pred_voting_hard_90),\n",
    "                                                     accuracy_score(y_train, y_pred_voting_soft)]},\n",
    "                                 columns=['Models', 'Accuracy score'])\n",
    "accuracy_score_df.sort_values('Accuracy score', inplace=True, ascending=False)\n",
    "accuracy_score_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(np.arange(len(accuracy_score_df['Models'])),\n",
    "         accuracy_score_df['Accuracy score'],\n",
    "         align='center',\n",
    "         height=0.5)\n",
    "\n",
    "plt.yticks(np.arange(len(accuracy_score_df['Models'])), accuracy_score_df['Models'])\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.xlabel('Accuracy score', fontdict={'fontsize': 13})\n",
    "plt.ylabel('Models', fontdict={'fontsize': 13})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different models' best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_df = pd.DataFrame({'Models': ['SVM',\n",
    "                                         'Decision Trees',\n",
    "                                         'Random Forest',\n",
    "                                         'AdaBoost',\n",
    "                                         'Extra Trees',\n",
    "                                         'Gradient Boosting'],\n",
    "                              'best_score_': [svr_gridsearch.best_score_,\n",
    "                                              decisionTree_gridsearch.best_score_,\n",
    "                                              rdmFrst_gridsearch.best_score_,\n",
    "                                              ada_gridsearch.best_score_,\n",
    "                                              extraTree_gridsearch.best_score_,\n",
    "                                              gbrt_gridsearch.best_score_]},\n",
    "                             columns=['Models', 'best_score_'])\n",
    "best_score_df.sort_values('best_score_', inplace=True, ascending=False)\n",
    "best_score_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(np.arange(len(best_score_df['Models'])), best_score_df['best_score_'], align='center', height=0.5)\n",
    "\n",
    "plt.yticks(np.arange(len(best_score_df['Models'])), best_score_df['Models'])\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.xlabel('best_score_', fontdict={'fontsize': 13})\n",
    "plt.ylabel('Models', fontdict={'fontsize': 13})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the root MSE of Random Forest model is the least among four models that we chose, I'll apply Random Forest to predict survivals in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = voting_soft_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerID_test = test_df['PassengerId']\n",
    "output_df = pd.DataFrame({'PassengerId':passengerID_test,\n",
    "                          'Survived': y_test},\n",
    "                         columns=['PassengerId', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('titanic_predict_survivals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kaggle Competition: [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview)\n",
    "- [Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)\n",
    "- [Titanic Top 4% with ensemble modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "- [An Interactive Data Science Tutorial](https://www.kaggle.com/helgejo/an-interactive-data-science-tutorial)\n",
    "- [handson-ml/03_classification.ipynb](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
