{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques\n",
    "Author: Jingwen ZHENG<br>\n",
    "Update: 2019-05-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- Project understanding\n",
    "- Objectif\n",
    "- Practice skills\n",
    "- Python packages to be applied\n",
    "- Import data\n",
    "- Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project understanding\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice skills\n",
    "- Creative feature engineering \n",
    "- Advanced regression techniques like random forest and gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python packages to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimension train_df:', train_df.shape)\n",
    "print('Dimension test_df:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing data in \"LotFrontage\", \"Alley\", \"MasVnrType\", \"MasVnrArea\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"Electrical\", \"FireplaceQu\", \"GarageType\", \"GarageYrBlt\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"PoolQC\", \"Fence\" and \"MiscFeature\".\n",
    "\n",
    "Among these fields,\n",
    "- 94% data of \"Alley\" are missing.\n",
    "- 47% data of \"FireplaceQu\" are missing.\n",
    "- 99.5% data of \"PoolQC\" are missing.\n",
    "- 81% data of \"Fence\" are missing.\n",
    "- 96% data of \"MiscFeature\" are missing.\n",
    "\n",
    "So we will ignore them during the analysis.\n",
    "\n",
    "What should we do on missing data of other fields? We might replace null by median value or mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['LotFrontage'].fillna(train_df['LotFrontage'].median(), inplace=True)\n",
    "train_df['MasVnrType'].fillna(train_df['MasVnrType'].value_counts().index[0], inplace=True)\n",
    "train_df['MasVnrArea'].fillna(train_df['MasVnrArea'].median(), inplace=True)\n",
    "train_df['BsmtQual'].fillna(train_df['BsmtQual'].value_counts().index[0], inplace=True)\n",
    "train_df['BsmtCond'].fillna(train_df['BsmtCond'].value_counts().index[0], inplace=True)\n",
    "train_df['BsmtExposure'].fillna(train_df['BsmtExposure'].value_counts().index[0], inplace=True)\n",
    "train_df['BsmtFinType1'].fillna(train_df['BsmtFinType1'].value_counts().index[0], inplace=True)\n",
    "train_df['BsmtFinType2'].fillna(train_df['BsmtFinType2'].value_counts().index[0], inplace=True)\n",
    "train_df['Electrical'].fillna(train_df['Electrical'].value_counts().index[0], inplace=True)\n",
    "train_df['GarageType'].fillna(train_df['GarageType'].value_counts().index[0], inplace=True)\n",
    "train_df['GarageYrBlt'].fillna(train_df['GarageYrBlt'].median(), inplace=True)\n",
    "train_df['GarageFinish'].fillna(train_df['GarageFinish'].value_counts().index[0], inplace=True)\n",
    "train_df['GarageQual'].fillna(train_df['GarageQual'].value_counts().index[0], inplace=True)\n",
    "train_df['GarageCond'].fillna(train_df['GarageCond'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['LotFrontage'].fillna(test_df['LotFrontage'].median(), inplace=True)\n",
    "test_df['MasVnrType'].fillna(test_df['MasVnrType'].value_counts().index[0], inplace=True)\n",
    "test_df['MasVnrArea'].fillna(test_df['MasVnrArea'].median(), inplace=True)\n",
    "test_df['BsmtQual'].fillna(test_df['BsmtQual'].value_counts().index[0], inplace=True)\n",
    "test_df['BsmtCond'].fillna(test_df['BsmtCond'].value_counts().index[0], inplace=True)\n",
    "test_df['BsmtExposure'].fillna(test_df['BsmtExposure'].value_counts().index[0], inplace=True)\n",
    "test_df['BsmtFinType1'].fillna(test_df['BsmtFinType1'].value_counts().index[0], inplace=True)\n",
    "test_df['BsmtFinType2'].fillna(test_df['BsmtFinType2'].value_counts().index[0], inplace=True)\n",
    "test_df['Electrical'].fillna(test_df['Electrical'].value_counts().index[0], inplace=True)\n",
    "test_df['GarageType'].fillna(test_df['GarageType'].value_counts().index[0], inplace=True)\n",
    "test_df['GarageYrBlt'].fillna(test_df['GarageYrBlt'].median(), inplace=True)\n",
    "test_df['GarageFinish'].fillna(test_df['GarageFinish'].value_counts().index[0], inplace=True)\n",
    "test_df['GarageQual'].fillna(test_df['GarageQual'].value_counts().index[0], inplace=True)\n",
    "test_df['GarageCond'].fillna(test_df['GarageCond'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "test_df.drop(columns=['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform some numerical variables that are really categorical\n",
    "train_df['MSSubClass'] = train_df['MSSubClass'].apply(str)\n",
    "train_df['OverallCond'] = train_df['OverallCond'].astype(str)\n",
    "train_df['YrSold'] = train_df['YrSold'].astype(str)\n",
    "train_df['MoSold'] = train_df['MoSold'].astype(str)\n",
    "\n",
    "test_df['MSSubClass'] = test_df['MSSubClass'].apply(str)\n",
    "test_df['OverallCond'] = test_df['OverallCond'].astype(str)\n",
    "test_df['YrSold'] = test_df['YrSold'].astype(str)\n",
    "test_df['MoSold'] = test_df['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice_per_squareFeet'] = train_df['SalePrice'] / train_df['LotArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.hist(bins=40, figsize=(16, 20), density=True)\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.45)#, top=0.97, bottom=0.03, left=0.04, right=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the group of histograms, we observed that most \"SalePrice\" is between 130k dollars(1st quartile) and 214k dollars(3rd quartile)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix between numerical values and \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20, 18)})\n",
    "num_fields = ['LotFrontage', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "              'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "              'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "              'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "              'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "              'PoolArea', 'MiscVal', 'SalePrice', 'SalePrice_per_squareFeet']\n",
    "\n",
    "sns.heatmap(train_df[num_fields].corr(),\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correlation heatmap shows, \"SalePrice\" is more related to \"OverallQual\", \"GrLivArea\" and \"GarageCars\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between \"SalePrice\" and numeric fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 7))\n",
    "fig, axarr = plt.subplots(nrows=6, ncols=3, figsize=(15, 30))\n",
    "\n",
    "axarr[0, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['BsmtFinSF1'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[0, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[0, 0].set_ylabel('Type 1 finished square feet (BsmtFinSF1)')\n",
    "axarr[0, 0].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[0, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['BsmtFinSF2'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[0, 1].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[0, 1].set_ylabel('Type 2 finished square feet (BsmtFinSF2)')\n",
    "axarr[0, 1].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[0, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['LotArea'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[0, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[0, 2].set_ylabel('Lot size in square feet (LotArea)')\n",
    "axarr[0, 2].set_ylim(bottom=-50)#, top=50000)\n",
    "\n",
    "axarr[1, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['YearBuilt'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[1, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[1, 0].set_ylabel('Original construction date (YearBuilt)')\n",
    "axarr[1, 0].set_ylim(bottom=1860)#, top=2500)\n",
    "\n",
    "axarr[1, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['YearRemodAdd'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[1, 1].set_xlabel('SalePrice')\n",
    "axarr[1, 1].set_ylabel('Remodel date (YearRemodAdd)')\n",
    "\n",
    "axarr[1, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['BsmtUnfSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[1, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[1, 2].set_ylabel('Unfinished square feet of \\nbasement area (BsmtUnfSF)')\n",
    "axarr[1, 2].set_ylim(bottom=-50)#, top=50000)\n",
    "\n",
    "axarr[2, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['TotalBsmtSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[2, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[2, 0].set_ylabel('Total square feet of basement area\\n(TotalBsmtSF)')\n",
    "axarr[2, 0].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[2, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['1stFlrSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[2, 1].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[2, 1].set_ylabel('First Floor square feet (1stFlrSF)')\n",
    "axarr[2, 1].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[2, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['2ndFlrSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[2, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[2, 2].set_ylabel('Second floor square feet (2ndFlrSF)')\n",
    "axarr[2, 2].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[3, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['GrLivArea'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[3, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[3, 0].set_ylabel('Above grade (ground) living area\\nsquare feet (GrLivArea)')\n",
    "axarr[3, 0].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[3, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['BedroomAbvGr'],\n",
    "                    s=30, \n",
    "                    alpha=0.2)\n",
    "axarr[3, 1].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[3, 1].set_ylabel('Number of bedrooms above\\nbasement level (BedroomAbvGr)')\n",
    "axarr[3, 1].set_ylim(bottom=-0.5)#, top=2500)\n",
    "\n",
    "axarr[3, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['KitchenAbvGr'],\n",
    "                    s=30, \n",
    "                    alpha=0.2)\n",
    "axarr[3, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[3, 2].set_ylabel('Number of kitchens (KitchenAbvGr)')\n",
    "axarr[3, 2].set_ylim(bottom=-0.2)#, top=2500)\n",
    "\n",
    "axarr[4, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['TotRmsAbvGrd'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[4, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[4, 0].set_ylabel('Total rooms above grade (does NOT\\ninclude bathrooms) (TotRmsAbvGrd)')\n",
    "axarr[4, 0].set_ylim(bottom=-0.2)#, top=2500)\n",
    "\n",
    "axarr[4, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['Fireplaces'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[4, 1].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[4, 1].set_ylabel('Number of fireplaces (Fireplaces)')\n",
    "axarr[4, 1].set_ylim(bottom=-0.2)#, top=2500)\n",
    "\n",
    "axarr[4, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['GarageArea'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[4, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[4, 2].set_ylabel('Size of garage in square feet\\n(GarageArea)')\n",
    "axarr[4, 2].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[5, 0].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['WoodDeckSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[5, 0].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[5, 0].set_ylabel('Wood deck area in square feet\\n(WoodDeckSF)')\n",
    "axarr[5, 0].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[5, 1].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['OpenPorchSF'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[5, 1].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[5, 1].set_ylabel('Open porch area in square feet\\n(OpenPorchSF)')\n",
    "axarr[5, 1].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "axarr[5, 2].scatter(x=train_df['SalePrice_per_squareFeet'],\n",
    "                    y=train_df['EnclosedPorch'],\n",
    "                    s=30,\n",
    "                    alpha=0.2)\n",
    "axarr[5, 2].set_xlabel('SalePrice per feet ($)')\n",
    "axarr[5, 2].set_ylabel('Enclosed porch area in square feet\\n(EnclosedPorch)')\n",
    "axarr[5, 2].set_ylim(bottom=-50)#, top=2500)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.2, wspace=0.3)#, top=0.97, bottom=0.03, left=0.04, right=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take parts of numeric values, show the relationship between \"SalePrice per square feet\" and each of them:\n",
    "\n",
    "- The more recent construction / remodel is, the higher \"SalePrice per square feet\" is.\n",
    "- The more total rooms above grade is, the higher \"SalePrice per square feet\" is.\n",
    "- The larger lot size (LotArea) is, the cheaper \"SalePrice per square feet\" is.\n",
    "- For the lot whose total basement area is not larger than 40 square feet, the larger total basement area is, the cheaper \"SalePrice per square feet\" is; for the lot whose total basement area is larger than 40 square feet, the \"SalePrice per square feet\" is between 500\\$ and 2000\\$.\n",
    "- For the lot whose above grade (groud) living area is not larger than 40 square feet, the large above grade (groud) living area is, the higher \"SalePrice per square feet\" is; for the lot whose above grade (groud) living area is larger than 40 square feet, the \"SalePrice per square feet\" is between 500\\$ and 2000\\$.\n",
    "- Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between \"SalePrice_per_squareFeet\" and category fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"1MSSubClass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "class_price_plt = sns.factorplot(data=train_df,\n",
    "                                 x='MSSubClass',\n",
    "                                 y='SalePrice_per_squareFeet',\n",
    "                                 size=6,\n",
    "                                 kind='bar',\n",
    "                                 palette='muted',\n",
    "                                 aspect=2)\n",
    "class_price_plt.despine(left=True)\n",
    "class_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all building classes, the first three most expensive classes are \"2-STORY PUD - 1946 & NEWER\", \"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\" and \"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"MSZoning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "zonecls_price_plt = sns.factorplot(data=train_df,\n",
    "                                 x='MSZoning',\n",
    "                                 y='SalePrice_per_squareFeet',\n",
    "                                 size=6,\n",
    "                                 kind='bar',\n",
    "                                 palette='muted',\n",
    "                                 aspect=2)\n",
    "zonecls_price_plt.despine(left=True)\n",
    "zonecls_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above studies the sale price per square feet in terms of general zoning classification. Among these 5 zoning classes, the sale price per square feet of \"Floating Village Residential (FV)\" is the most expensive, the zoning classes which are less expensive are \"Residential Medium Density (RM)\", \"Residential High Density (RH)\" and \"Residential Low Density (RL)\", the sale price per square feet of \"Commercial (C)\" is the cheapest among the 5 classes.\n",
    "\n",
    "Considering the construction's difficulty and their rarity, we can obviously understand why the sale price per square feet of \"Floating Village Residential (FV)\" is the most expensive. However, there are less restrictions on the \"Commercial\" class, so it's the cheapest class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"LotShape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "lotshape_price_plt = sns.factorplot(data=train_df,\n",
    "                                 x='LotShape',\n",
    "                                 y='SalePrice_per_squareFeet',\n",
    "                                 size=6,\n",
    "                                 kind='bar',\n",
    "                                 palette='muted',\n",
    "                                 aspect=2)\n",
    "lotshape_price_plt.despine(left=True)\n",
    "lotshape_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between General shape of property (LotShape) and the sale price per square feet is easily to understand: people usually like regular shape (Reg) of property, since it's simple for the overall arrangement and more confortable for living."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"Utilities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "utility_price_plt = sns.factorplot(data=train_df,\n",
    "                                 x='Utilities',\n",
    "                                 y='SalePrice_per_squareFeet',\n",
    "                                 size=6,\n",
    "                                 kind='bar',\n",
    "                                 palette='muted',\n",
    "                                 aspect=2)\n",
    "utility_price_plt.despine(left=True)\n",
    "utility_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this plot is interesting: we all know the more complete utilities are, the more expensive per square feet is. Except this point, we also get the price per square feet of a property whose all public utilities are available is double of the square feet-price of a property that only electricity and gas are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"LotConfig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "lotconfig_price_plt = sns.factorplot(data=train_df,\n",
    "                                     x='LotConfig',\n",
    "                                     y='SalePrice_per_squareFeet',\n",
    "                                     size=6,\n",
    "                                     kind='bar',\n",
    "                                     palette='muted',\n",
    "                                     aspect=2)\n",
    "lotconfig_price_plt.despine(left=True)\n",
    "lotconfig_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the lightness, the ventilation and the view, the lot with \"Frontage on 3 sides of property\" is the best, so its price per square feet is the most expensive among the 5 configurations. On the contrary, the lot which is located as a Cul-de-sac, its price per square feet is the cheapest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"Neighborhood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "neighbor_price_plt = sns.factorplot(data=train_df,\n",
    "                                       x='Neighborhood',\n",
    "                                       y='SalePrice_per_squareFeet',\n",
    "                                       size=6,\n",
    "                                       kind='bar',\n",
    "                                       palette='muted',\n",
    "                                       aspect=2)\n",
    "neighbor_price_plt.despine(left=True)\n",
    "neighbor_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "neighbor_price_plt.set_xticklabels(rotation=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the economic / political / geographical reasons, if a lot is located near Bluestem, its price per square feet is nearly 90 dollars; moreover, if a lot is located near Bloomington Heights or Briardale, its price per square feet is about 60 dollars. However, if a lot is located near Clear Creek, its unit price is only about 15 dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"OverallQual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "overallQual_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='OverallQual',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "overallQual_price_plt.despine(left=True)\n",
    "overallQual_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The better the overall material is, the more expensive the lot is. The interesting point is median value of square feet price of \"very excellent\" lot is a little bit lower than \"excellent\" ones, but its variance is more than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"RoofMatl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "roofMatl_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='RoofMatl',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "roofMatl_price_plt.despine(left=True)\n",
    "roofMatl_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the insulation, drainage, material cost and robustness, the lot with Standard (Composite) Shingle roof or Wood Shingles roof is more expensive than others. However, if a lot's roof is constucted by Clay or Tile, it's the relatively cheapest (per square feet) since its function is not as well as others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"Heating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "heating_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='Heating',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "heating_price_plt.despine(left=True)\n",
    "heating_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering material cost and construction-difficulties, the lot with \"Gas forced warm air furnace\" heating is more expensive than other heating types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"GarageType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "garageType_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='GarageType',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "garageType_price_plt.despine(left=True)\n",
    "garageType_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering construction and property's convenience, the lot with built-in garage is more expensive than other types of garage, the lot only with car port as the garage is the cheapest in terms of per square feet's price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"SaleType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "saleType_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='SaleType',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "saleType_price_plt.despine(left=True)\n",
    "saleType_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about the impact of sale type on the sale price. There is no doubt that the new lot which is just constructed and sold is the most expensive because its loss is the least. But I'm not clear for the reason of why other types of sale are less expensive. If you know why, your ideas are welcome :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SalePrice_per_squareFeet\" vs. \"SaleCondition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 12))\n",
    "saleCdt_price_plt = sns.factorplot(data=train_df,\n",
    "                                    x='SaleCondition',\n",
    "                                    y='SalePrice_per_squareFeet',\n",
    "                                    size=6,\n",
    "                                    kind='bar',\n",
    "                                    palette='muted',\n",
    "                                    aspect=2)\n",
    "saleCdt_price_plt.despine(left=True)\n",
    "saleCdt_price_plt.set_ylabels('SalePrice per square feet ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all sold lots, a lot is more expensive than others if it was not completed when last assessed (associated with New Homes), but it's less expensive for the adjoining land purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_attribs = train_df.drop(columns=['MSSubClass', 'OverallCond',\n",
    "#                                      'MoSold', 'YrSold',\n",
    "#                                      'SalePrice_per_squareFeet',\n",
    "#                                      'SalePrice']).dtypes[train_df.dtypes != \"object\"].index\n",
    "\n",
    "num_attribs = train_df.drop(columns=['MSSubClass', 'OverallCond',\n",
    "                                     'MoSold', 'YrSold',\n",
    "                                     'SalePrice_per_squareFeet',\n",
    "                                     'SalePrice']).dtypes[train_df.dtypes != \"object\"].index\n",
    "\n",
    "cat_attribs = ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'OverallCond',\n",
    "               'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
    "               'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "               'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "               'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir',\n",
    "               'Electrical', 'KitchenQual', 'Functional', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "               'GarageCond', 'PavedDrive', 'YrSold', 'MoSold', 'SaleType', 'SaleCondition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process columns, apply LabelEncoder to categorical features\n",
    "for col in cat_attribs:\n",
    "    lbl_train = LabelEncoder() \n",
    "    lbl_train.fit(list(train_df[col].values)) \n",
    "    train_df[col] = lbl_train.transform(list(train_df[col].values))\n",
    "\n",
    "for col in cat_attribs:\n",
    "    lbl_test = LabelEncoder() \n",
    "    lbl_test.fit(list(test_df[col].values)) \n",
    "    test_df[col] = lbl_test.transform(list(test_df[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed features for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, boxcox_normmax\n",
    "skewed_train_df = train_df[num_attribs].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skewed_test_df = test_df[num_attribs].apply(lambda x: skew(x)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box Cox Transformation of (highly) skewed features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_skewed_train_var = skewed_train_df[skewed_train_df > 0.5]\n",
    "high_skewed_test_var = skewed_test_df[skewed_test_df > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "high_skewed_train_idx = high_skewed_train_var.index\n",
    "high_skewed_test_idx = high_skewed_test_var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in high_skewed_train_idx:\n",
    "    train_df[idx] = boxcox1p(train_df[idx], boxcox_normmax(train_df[idx] + 1))\n",
    "\n",
    "for idx in high_skewed_test_idx:\n",
    "    test_df[idx] = boxcox1p(test_df[idx], boxcox_normmax(test_df[idx] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF']\n",
    "test_df['TotalSF'] = test_df['TotalBsmtSF'] + test_df['1stFlrSF'] + test_df['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# apply log(1+x) to all 'SalePrice'\n",
    "train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\n",
    "\n",
    "X = train_df.drop(columns=['Id', 'SalePrice_per_squareFeet', 'SalePrice'])\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=0.25,\n",
    "                                                                random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_rg = LinearRegression()\n",
    "lin_rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin_rg = lin_rg.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_lin_rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_rg = Ridge(alpha=1, solver='cholesky', random_state=42)\n",
    "ridge_rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge_rg = ridge_rg.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_ridge_rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_rg = Lasso(alpha=0.001, random_state=42)\n",
    "lasso_rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lasso_rg = lasso_rg.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_lasso_rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.004, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_elastic_net = elastic_net.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_elastic_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Ridge Regression, Lasso Regression and Elastic Net with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [1, 5, 10, 14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.001, 0.005, 0.01, 0.05]\n",
    "e_alphas = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "e_l1ratio = [0.5, 0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "\n",
    "ridge_rg_CV = RidgeCV(alphas=alphas_alt, cv=kfolds)\n",
    "lasso_rg_CV = LassoCV(max_iter=1e7, alphas=alphas2, cv=kfolds, random_state=42)\n",
    "elastic_net_CV = ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio, random_state=42)\n",
    "\n",
    "ridge_rg_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_rg_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge_rg_CV = ridge_rg_CV.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_ridge_rg_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lasso_rg_CV = lasso_rg_CV.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_lasso_rg_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_elastic_net_CV = elastic_net_CV.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_elastic_net_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_mdl = SVR(C=20, epsilon=0.008, gamma=0.0001)\n",
    "svr_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svr = svr_mdl.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsvr = LinearSVR(epsilon=0.05, random_state=42)\n",
    "lsvr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linSVR = lsvr.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_linSVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4,\n",
    "                                max_features='sqrt', min_samples_leaf=15, min_samples_split=10,\n",
    "                                loss='huber', random_state =42)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbr = gbr.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Grandient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM and gcc 8 in MacOS: `Library not loaded: /usr/local/opt/gcc/lib/gcc/7/libgomp.1.dylib`\n",
    "<https://github.com/microsoft/LightGBM/issues/1369>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# lightgbr = LGBMRegressor(objective='regression',\n",
    "#                          num_leaves=4,\n",
    "#                          learning_rate=0.01,\n",
    "#                          n_estimators=5000,\n",
    "#                          max_bin=200,\n",
    "#                          bagging_fraction=0.75,\n",
    "#                          bagging_freq=5,\n",
    "#                          bagging_seed=7,\n",
    "#                          feature_fraction=0.2,\n",
    "#                          feature_fraction_seed=7,\n",
    "#                          verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgbr = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgbr = xgbr.predict(X_validation)\n",
    "rmsle(y_validation, y_pred_xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "- Gradient Boosting Regressor: revise\n",
    "- Light Grandient Boosting Regressor: intro, parameters\n",
    "- XGBoost Regressor: intro, parameters\n",
    "- Stacking: revise, StackingCVRegressor()\n",
    "- How to optimise parameters for the models above?\n",
    "- Blending models ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "stacking_rg = StackingCVRegressor(regressors=(ridge_rg_CV, lasso_rg_CV, elastic_net_CV, gbr, xgbr),# lightgbm),\n",
    "                                meta_regressor=xgbr,\n",
    "                                use_features_in_secondary=True)\n",
    "stacking_rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_stacking = stacking_rg.predict(X_validation)\n",
    "# rmsle(y_validation, y_pred_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = xgbr.predict(test_df.drop(columns='Id'))\n",
    "\n",
    "# Inspired by \"What is the inverse of numpy's log1p?\"\n",
    "# <https://stackoverflow.com/questions/50049891/what-is-the-inverse-of-numpys-log1p>\n",
    "y_test = np.expm1(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df['Id']\n",
    "output_df = pd.DataFrame({'Id':test_id,\n",
    "                          'SalePrice': y_test},\n",
    "                         columns=['Id', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('house_price_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- House Prices: Advanced Regression Techniques\n",
    "    <https://www.kaggle.com/jesucristo/1-house-prices-solution-top-1>\n",
    "- Stacked Regressions to predict House Prices\n",
    "    <https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
